{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/santiagovazquezff/circuit_fault_detection/blob/main/demo/demo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Demo for circuit_fault_pipeline**"
      ],
      "metadata": {
        "id": "R4GUa4T3J0-Q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This demo shows how our trained Random Forest model classifies circuit states (healthy / open / short) from waveform data.\n",
        "\n",
        "## How to use\n",
        "1. Click on the blue (`Open in Colab`) button at the top to open the demo in Google Colab (a cloud based Python notebook for ML)\n",
        "2. In Google Colab run all cells (`Runtime > Run all`) to execute the code\n",
        "3. As stated in the command window when ran, upload one of the sample CSV files from circuit_fault_detection/demo/ in the GitHub repo (you can upload your own simulated CSV from Altium, consult the lab report)\n",
        "4. As also stated in the command window, enter input amplitude and frequency for the data on the CSV file (a dictionary for the sample CSV files with the corresponding amplitudes and frequencies is provided below)\n",
        "5. View predicted class, probabilities, and waveform plot"
      ],
      "metadata": {
        "id": "lRIk3MqOg77h"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Imports and file loading"
      ],
      "metadata": {
        "id": "v3rpO8cpKiCT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os, sys, json, numpy as np, pandas as pd, joblib\n",
        "import matplotlib.pyplot as plt\n",
        "from collections import Counter\n",
        "\n",
        "file_dictionary = {\n",
        "  \"demo_file_1\": {\"amplitude\": 0.283,\n",
        "                  \"frequency\": 200},\n",
        "  \"demo_file_2\": {\"amplitude\": 0.283,\n",
        "                  \"frequency\": 200},\n",
        "  \"demo_file_3\": {\"amplitude\": 0.283,\n",
        "                  \"frequency\": 200}\n",
        "  }\n",
        "\n",
        "!mkdir -p model_artifacts\n",
        "!wget -q https://raw.githubusercontent.com/santiagovazquezff/circuit_fault_detection/main/model_artifacts/rf_model.joblib -O model_artifacts/rf_model.joblib\n",
        "!wget -q https://raw.githubusercontent.com/santiagovazquezff/circuit_fault_detection/main/model_artifacts/meta.json     -O model_artifacts/meta.json\n",
        "\n",
        "rf = joblib.load(\"model_artifacts/rf_model.joblib\")\n",
        "with open(\"model_artifacts/meta.json\") as f:\n",
        "    meta = json.load(f)\n",
        "\n",
        "classes = meta.get(\"classes\", [])\n",
        "feat_names = meta.get(\"features\", [])\n",
        "expects_f0 = (\"f0\" in feat_names)\n",
        "\n",
        "print(\"Model loaded\")\n",
        "print(\"Classes:\", classes)\n",
        "print(\"Feature order:\", feat_names)"
      ],
      "metadata": {
        "id": "tbGKKH_Nw0a8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## User inputs - **follow instructions in terminal window**"
      ],
      "metadata": {
        "id": "z3II6D1fKnXG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "print(\"\"\"\n",
        "\\n\\033[1mInstructions for uploading demo files:\\033[0m\n",
        "\\n1. In the GitHub repo santiagovazquezff/circuit_fault_detection/demo, select one of the CSV files included:\"\"\")\n",
        "print(\"\\nFile dictionary:\")\n",
        "print(file_dictionary)\n",
        "print(\"\"\"\n",
        "2. Click on the \"download raw file\" button to download the file\n",
        "\\n3. Upload the file in the box below\n",
        "\"\"\")\n",
        "uploaded = files.upload()\n",
        "csv_files = list(uploaded.keys())\n",
        "if not csv_files:\n",
        "    raise SystemExit(\"No CSVs uploaded.\")\n",
        "\n",
        "vin_pk = float(input(\"\\nEnter input amplitude of waveform uploaded [consult dictionary below step 1 terminal window]: \") or 0.283)\n",
        "f0     = float(input(\"\\nEnter excitation frequency of waveform uploaded [consult dictionary below step 1 terminal window]: \"))"
      ],
      "metadata": {
        "id": "U-St2_OuKHYd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model functions and uploaded data processing"
      ],
      "metadata": {
        "id": "S-svB29pK3_e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "TIME_WINDOW, N_POINTS = 0.1, 16384\n",
        "\n",
        "def read_df(df):\n",
        "    assert \"s\" in df.columns, \"CSV must have a 's' time column (seconds).\"\n",
        "    t = df[\"s\"].to_numpy(float)\n",
        "    V = df.iloc[:, 1:].to_numpy(float)\n",
        "    if V.ndim == 1:\n",
        "        V = V[:, None]\n",
        "    return t, V\n",
        "\n",
        "def standardise(t, v, time_window=TIME_WINDOW, n_points=N_POINTS):\n",
        "    t0 = float(t[0])\n",
        "    mask = (t - t0) < time_window\n",
        "    t2, v2 = t[mask], v[mask]\n",
        "    if t2.size < 2:\n",
        "        raise ValueError(\"Not enough points inside the time window for interpolation.\")\n",
        "    t_fit = np.linspace(0.0, time_window, n_points, endpoint=False)\n",
        "    v_fit = np.interp(t_fit, t2 - t0, v2)\n",
        "    return t_fit, v_fit\n",
        "\n",
        "def lockin_features(v_fit, t_fit, f0_hz):\n",
        "    x, tt = v_fit.astype(float), t_fit.astype(float)\n",
        "    dc = float(np.mean(x)); xz = x - dc; N = x.size\n",
        "    def ap(freq):\n",
        "        w = 2*np.pi*freq\n",
        "        c = np.cos(w*tt); s = np.sin(w*tt)\n",
        "        a = (2.0/N)*np.dot(xz, c); b = (2.0/N)*np.dot(xz, s)\n",
        "        A = float(np.hypot(a, b)); ph = float(np.arctan2(-b, a))\n",
        "        return A, ph\n",
        "    A1, ph = ap(f0_hz); A2,_ = ap(2*f0_hz); A3,_ = ap(3*f0_hz)\n",
        "    thd = (np.sqrt(A2**2 + A3**2)/A1) if A1 > 0 else 0.0\n",
        "    ms_total = float(np.mean(x**2)); ms_dc = dc**2\n",
        "    ms_tones = (A1**2 + A2**2 + A3**2)/2.0\n",
        "    noise_rms = float(np.sqrt(max(ms_total - ms_dc - ms_tones, 0.0)))\n",
        "    return A1, ph, thd, noise_rms, A2, A3\n",
        "\n",
        "def features_from_df(df, f0_hz, vin_pk_val, include_f0=True):\n",
        "    t, V = read_df(df)\n",
        "    rows = []\n",
        "    for k in range(V.shape[1]):\n",
        "        t_fit, v_fit = standardise(t, V[:, k])\n",
        "        A1, ph, thd, noise_rms, A2, A3 = lockin_features(v_fit, t_fit, f0_hz)\n",
        "        feats = [A1/vin_pk_val, ph, thd, noise_rms/vin_pk_val, A2/vin_pk_val, A3/vin_pk_val]\n",
        "        if include_f0:\n",
        "            feats.append(float(f0_hz))\n",
        "        rows.append(feats)\n",
        "    return np.array(rows, float), t, V\n",
        "\n",
        "def predict_with_features(X):\n",
        "    preds = rf.predict(X)\n",
        "    proba = rf.predict_proba(X).mean(axis=0)  # average confidence across runs\n",
        "    maj, cnt = Counter(preds).most_common(1)[0]\n",
        "    return preds, proba, maj, cnt\n",
        "\n",
        "for fname in csv_files:\n",
        "    print(\"\\n\" + \"-\"*80)\n",
        "    print(\"File:\", fname)\n",
        "    df = pd.read_csv(fname)\n",
        "\n",
        "    X_with, t_raw, V_raw = features_from_df(df, f0_hz=f0, vin_pk_val=vin_pk, include_f0=expects_f0)\n",
        "    preds_w, proba_w, maj_w, cnt_w = predict_with_features(X_with)"
      ],
      "metadata": {
        "id": "R2_PjE9NKM5j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Results for data uploaded - **see terminal window**"
      ],
      "metadata": {
        "id": "SoTGR_ODLCUv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "    print(f\"\\n\\n\\033[1mFINAL PREDICTION: {maj_w}  ({cnt_w}/{len(preds_w)} runs)\\033[0m \")\n",
        "    print(\"\\nClass probabilities:\")\n",
        "    for cls, p in zip(rf.classes_, proba_w):\n",
        "        print(f\"  {cls}: {p:.3f}\")\n",
        "\n",
        "    run0 = V_raw[:, 0]\n",
        "    ms_window = 15e-3\n",
        "    mask_vis = (t_raw - t_raw[0]) < ms_window\n",
        "    t_vis = (t_raw[mask_vis] - t_raw[0]) * 1e3  # ms\n",
        "    v_vis = run0[mask_vis]\n",
        "\n",
        "    print(\"\\nPlot of raw data for user to confirm prediction as either healthy, open, or short:\")\n",
        "    plt.figure(figsize=(6.2, 3.6))\n",
        "    plt.plot(t_vis, v_vis)\n",
        "    plt.xlabel(\"Time [ms]\")\n",
        "    plt.ylabel(\"Vout [V]\")\n",
        "    plt.title(f\"{fname} â€” waveform (first 15 ms). Predicted (with f0): {maj_w}\")\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "2ane5kPbKQd_"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
